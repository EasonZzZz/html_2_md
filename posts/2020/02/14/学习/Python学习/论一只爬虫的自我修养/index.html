<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>论一只爬虫的自我修养 | Nice To Meet U</title><meta name="description" content="论一只爬虫的自我修养"><meta name="keywords" content="Python,爬虫"><meta name="author" content="EasonZzZz"><meta name="copyright" content="EasonZzZz"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="论一只爬虫的自我修养"><meta name="twitter:description" content="论一只爬虫的自我修养"><meta name="twitter:image" content="https://api.dujin.org/bing/1920.php"><meta property="og:type" content="article"><meta property="og:title" content="论一只爬虫的自我修养"><meta property="og:url" content="http://yoursite.com/2020/02/14/学习/Python学习/论一只爬虫的自我修养/"><meta property="og:site_name" content="Nice To Meet U"><meta property="og:description" content="论一只爬虫的自我修养"><meta property="og:image" content="https://api.dujin.org/bing/1920.php"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.15/dist/snackbar.min.css"><link rel="canonical" href="http://yoursite.com/2020/02/14/学习/Python学习/论一只爬虫的自我修养/"><link rel="prev" title="正则表达式" href="http://yoursite.com/2020/02/16/学习/Python学习/正则表达式/"><link rel="next" title="Python模块" href="http://yoursite.com/2020/02/14/学习/Python学习/Python模块/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://easonzzzz.github.io/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'true',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false,
  ClickShowText: undefined,
  medium_zoom: 'false',
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"}
  
}</script></head><body><div id="header"> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Nice To Meet U</a></span><i class="fa fa-bars fa-fw toggle-menu pull_right close" aria-hidden="true"></i><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 目录</span></a></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="https://raw.githubusercontent.com/EasonZzZz/BlogPic/master/img/20191025120143.png" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">106</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">41</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">10</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 目录</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#入门"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text"> 入门</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#编码"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text"> 编码</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#下载一只猫"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text"> 下载一只猫</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#更好的选择"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text"> 更好的选择</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#安装-requests"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text"> 安装 Requests</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#安装-beautifulsoup4"><span class="toc_mobile_items-number">4.2.</span> <span class="toc_mobile_items-text"> 安装 BeautifulSoup4</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#爬取豆瓣-top250-电影排行榜"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text"> 爬取豆瓣 Top250 电影排行榜</span></a></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#入门"><span class="toc-number">1.</span> <span class="toc-text"> 入门</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#编码"><span class="toc-number">2.</span> <span class="toc-text"> 编码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#下载一只猫"><span class="toc-number">3.</span> <span class="toc-text"> 下载一只猫</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#更好的选择"><span class="toc-number">4.</span> <span class="toc-text"> 更好的选择</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#安装-requests"><span class="toc-number">4.1.</span> <span class="toc-text"> 安装 Requests</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装-beautifulsoup4"><span class="toc-number">4.2.</span> <span class="toc-text"> 安装 BeautifulSoup4</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#爬取豆瓣-top250-电影排行榜"><span class="toc-number">5.</span> <span class="toc-text"> 爬取豆瓣 Top250 电影排行榜</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://api.dujin.org/bing/1920.php)"><div id="post-info"><div id="post-title"><div class="posttitle">论一只爬虫的自我修养</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-02-14<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-02-16</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Python学习/">Python学习</a></span><div class="post-meta-wordcount"><i class="fa fa-eye post-meta__icon" aria-hidden="true">       </i><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="入门"><a class="markdownIt-Anchor" href="#入门"></a> 入门</h1>
<p>网络爬虫，又称网页蜘蛛(WebSpider)，非常形象的一个名字。互联网是蛛网，而蜘蛛在网上爬，以获取资源。<br>
百度或谷歌这样的搜索引擎检索到需要的网页，就是靠它们的爬虫在互联网上，对每个关键词进行索引，建立索引数据库。经过复杂的算法排序后，这些结果将按照与搜索关键词相关度的高低依次排。<br>
编写一个搜索引擎，十分困难。但是我们可以从最简单的网络爬虫开始，不断改进。<br>
Python 中提供了 <strong>urllib(url+lib)</strong> 模块，可以让 Python 接入互联网。</p>
<ul>
<li>URL 的一般格式（带 方括号[] 为可选项）</li>
</ul>
<blockquote>
<p><strong>protocol</strong>: // <strong>hostname[: port]</strong> / <strong>path</strong> / [;parameters] [?query] # fragemnt</p>
</blockquote>
<ul>
<li>
<p>URL 由三部分组成：</p>
<ul>
<li><strong>协议(protocol)</strong>，常见有 http、https、ftp、file、ed2k</li>
<li>存放资源的服务器的 <strong>域名系统(DNS)</strong> 主机名或 IP 地址（有时候要包括端口号，各种协议都有默认端口号）</li>
<li><strong>主机资源的具体地址</strong></li>
</ul>
</li>
<li>
<p>在 Python3 中，urllib 其实是一个包，它包括了 urllib 和urllib2，统一命名为 urllib。这个包中有四个模块：</p>
<ul>
<li><strong>urllib.request</strong> for opening and reading URLs，这是做重要的模块</li>
<li><strong>urllib.error</strong> containing the exceptions raised by <strong>urllib.request</strong></li>
<li><strong>urllib.parse</strong> for parsing URLs</li>
<li><strong>urllib.robotparse</strong>r for parsing robots.txt files</li>
</ul>
</li>
<li>
<p>Python 爬取内容是以 utf-8 编码的 bytes 对象（打印字符串前有个 b，表示这是一个 bytes 对象），要还原成 html 代码，需要对其进行解码。</p>
</li>
</ul>
<h1 id="编码"><a class="markdownIt-Anchor" href="#编码"></a> 编码</h1>
<p>为了解决不同国家不同标准的编码方法，<strong>Unicode</strong> 编码应运而生。它的做法十分简单：创建一个足够大的编码，将所有国家的编码都加进来，统一标准。<br>
而且，为了能节省空间，Unicode 还创造了很多种实现方式。</p>
<ul>
<li>UTF-8 就是 Unicode 的常见实现方式，是一种可变长编码</li>
<li>简单来说，就是当文本时 ASCII 编码的字符时，用 1 字节存放；而文本是其他 Unicode 字符时，按一定算法转换，每个字符使用 1-3 个字节存放。</li>
</ul>
<h1 id="下载一只猫"><a class="markdownIt-Anchor" href="#下载一只猫"></a> 下载一只猫</h1>
<p>我们可以在 <a href="http://placekitten.com" target="_blank" rel="noopener">http://placekitten.com</a> 尝试下载一张猫的图片。在这个网址后面附上宽度和高度，就可以得到一只随机的猫。</p>
<ul>
<li><a href="http://placekitten.com/200/300" target="_blank" rel="noopener">http://placekitten.com/200/300</a> 得到一张宽度为 200 像素，高度为 300 像素的图片</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://placekitten.com/200/300'</span>)</span><br><span class="line">cat_img = response.read()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'cat_200_300.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(cat_img)</span><br></pre></td></tr></table></figure>
<p>执行上面代码，就能在文件夹中看到猫的照片了<br>
其实，urlopen() 的参数可是一个字符串也可以是 Request 对象。如果是一个字符串，会默认被转为 Request 对象再传入。<br>
因此，代码也可以这样写：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">req = urllib.request.Request(<span class="string">'http://placekitten.com/200/300'</span>)</span><br><span class="line">response = urllib.request.urlopen(req)</span><br></pre></td></tr></table></figure>
<p>urlopen() 实际上返回一个类文件对象，因此用 read() 方法来读取内容，除此之外，文档还告诉我们这个类文件对象还能使用以下三个函数：</p>
<ul>
<li>geturl()：返回请求的 url，通常用于判断是否重定向</li>
<li>info()：返回一个 httplib.HTTPMessage 对象，包含远程服务器返回的头信息</li>
<li>getcode()：返回 HTTP 状态码</li>
</ul>
<h1 id="更好的选择"><a class="markdownIt-Anchor" href="#更好的选择"></a> 更好的选择</h1>
<p>通常情况下，Python 官方提供的“电池”都是最可靠和实用的，除了 urllib。因为，还有一个比 urllib 更好的 HTTP 库——Requests</p>
<h2 id="安装-requests"><a class="markdownIt-Anchor" href="#安装-requests"></a> 安装 Requests</h2>
<p>与之前安装 EasyGui 一样，使用 pip 命令安装即可</p>
<h2 id="安装-beautifulsoup4"><a class="markdownIt-Anchor" href="#安装-beautifulsoup4"></a> 安装 BeautifulSoup4</h2>
<p>有了 Requests 模块，就可以用它的 get() 方法从服务器上下载网页。但是下载的是网页源代码，不利于检索数据，因而我们需要一个解析器。<br>
推荐使用 <strong>BeautifulSoup4(BS4)</strong>，这是一个网页解析利器。安装方法也是用 pip 命令安装</p>
<h1 id="爬取豆瓣-top250-电影排行榜"><a class="markdownIt-Anchor" href="#爬取豆瓣-top250-电影排行榜"></a> 爬取豆瓣 Top250 电影排行榜</h1>
<p>这是我初中就开始看的排行榜，看的电影基本都在上面找的。虽然有些电影已经很老了，但是经典不会随着时间消去的，建议观看。<br>
使用 Requests 下载这个榜单非常简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0'</span>,</span><br><span class="line">&#125;</span><br><span class="line">res = requests.get(<span class="string">'https://movie.douban.com/top250'</span>, headers=headers)</span><br><span class="line">soup = bs4.BeautifulSoup(res.text, <span class="string">'html.parser'</span>)</span><br><span class="line">targets = soup.find_all(<span class="string">'div'</span>, class_=<span class="string">'hd'</span>)</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> targets:</span><br><span class="line">    print(each.a.span.text)</span><br></pre></td></tr></table></figure>
<ul>
<li>由于豆瓣有反爬虫机制，我刚开始没加 headers，然后 status_code 一直返回 418，于是百度了一番，加上了 headers，居然就可以了。至于 headers 是什么？我也不知道，计网应该会学的</li>
</ul>
<p>这些数据是什么来的？看一下 HTML 源代码。<br>
<img alt data-src="https://raw.githubusercontent.com/EasonZzZz/BlogPic/master/img/20200215115412.png" class="lazyload"><br>
每部电影的标题都位于 <strong>&lt;div class=‘hd’&gt;…&lt;/div&gt;</strong> 的标签中，它的从属关系是 div-&gt;a-&gt;span<br>
所以先调用 <strong>find_all()</strong> 方法，找到所有 <strong>class=‘hd’</strong> 的 div 标签，然后按从属关系直接取出电影名。<br>
现在我们把所有的数据爬出来吧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_url</span><span class="params">(url)</span>:</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_movies</span><span class="params">(res)</span>:</span></span><br><span class="line">    soup = bs4.BeautifulSoup(res.text, <span class="string">'html.parser'</span>)</span><br><span class="line">    <span class="comment"># 电影名</span></span><br><span class="line">    movies = []</span><br><span class="line">    targets = soup.find_all(<span class="string">'div'</span>, class_=<span class="string">'hd'</span>)</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> targets:</span><br><span class="line">        movies.append(each.a.span.text)</span><br><span class="line">    <span class="comment"># 评分</span></span><br><span class="line">    ranks = []</span><br><span class="line">    targets = soup.find_all(<span class="string">'span'</span>, class_=<span class="string">'rating_num'</span>)</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> targets:</span><br><span class="line">        ranks.append(<span class="string">' 评分：%s '</span> % each.text)</span><br><span class="line">    <span class="comment"># 资料</span></span><br><span class="line">    messages = []</span><br><span class="line">    targets = soup.find_all(<span class="string">'div'</span>, class_=<span class="string">'bd'</span>)</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> targets:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            messages.append(each.p.text.split(<span class="string">'\n'</span>)[<span class="number">1</span>].strip() + each.p.text.split(<span class="string">'\n'</span>)[<span class="number">2</span>].strip())</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line">    length = len(movies)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(length):</span><br><span class="line">        result.append(movies[i] + ranks[i] + messages[i] + <span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找出一共几个页面</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_depth</span><span class="params">(res)</span>:</span></span><br><span class="line">    soup = bs4.BeautifulSoup(res.text, <span class="string">'html.parser'</span>)</span><br><span class="line">    depth = soup.find(<span class="string">'span'</span>, class_=<span class="string">'next'</span>).previous_sibling.previous_sibling.text</span><br><span class="line">    <span class="keyword">return</span> int(depth)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    host = <span class="string">"https://movie.douban.com/top250"</span></span><br><span class="line">    res = open_url(host)</span><br><span class="line">    depth = find_depth(res)</span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(depth):</span><br><span class="line">        url = host + <span class="string">'/?start='</span> + str(<span class="number">25</span>*i)</span><br><span class="line">        res = open_url(url)</span><br><span class="line">        result.append(find_movies(res))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'豆瓣Top250电影.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> result:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> each:</span><br><span class="line">                f.write(i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">EasonZzZz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/02/14/学习/Python学习/论一只爬虫的自我修养/">http://yoursite.com/2020/02/14/学习/Python学习/论一只爬虫的自我修养/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com">Nice To Meet U</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python    </a><a class="post-meta__tags" href="/tags/爬虫/">爬虫    </a></div><div class="post_share"></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/02/16/学习/Python学习/正则表达式/"><img class="prev_cover lazyload" data-src="https://api.dujin.org/bing/1920.php" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>正则表达式</span></div></a></div><div class="next-post pull_right"><a href="/2020/02/14/学习/Python学习/Python模块/"><img class="next_cover lazyload" data-src="https://source.unsplash.com/collection/collectionid/1600x900" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>Python模块</span></div></a></div></nav></div></div><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By EasonZzZz</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script async src="/js/search/local-search.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.15/dist/snackbar.min.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async></script><script src="/js/third-party/click_heart.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>